\section{Confronto tra modelli}
I quattro modelli addestrati portano tutti a ottime performance, ma i loro 
tempi di addestramento variano notevolmente.
Per scegliere il modello migliore vengono quindi analizzati sia l'accuratezza
bilanciata sia il tempo di addestramento.

Per calcolare valore medio e intervallo di confidenza di entrambe
le misurazioni, viene eseguita
una stratified cross-validation con 10 fold. Questo numero di fold è stato 
scelto perchè esperimenti passati hanno dimostrato che un tale numero di fold
permette di approssimare bene i valori reali.

Per quanto riguarda l'accuratezza bilanciata, tutti i modelli presentano un
valore medio maggiore del $90\%$. In particolare, i valori medi dei quattro modelli
sono: \begin{itemize*}
    \item albero decisionale = $91,5\%$
    \item MLP = $93,1\%$
    \item SVM = $93,9\%$
    \item Gaussian Naive Bayes = $91,5\%$
\end{itemize*}
Gli intervalli di confidenza al $90\%$ dell'accuratezza bilanciata sono invece:
\begin{itemize*}
    \item albero decisionale = $(91,1\%, 91,9\%)$
    \item MLP = $(92,7\%, 93,5\%)$
    \item SVM = $(93,7\%, 94,1\%)$
    \item Gaussian Naive Bayes = $(91,2\%, 91,8\%)$
\end{itemize*}
Il modello con le performance migliori è, quindi, la SVM. Albero decisionale e
Gaussian Naive Bayes presentano, invece, prestazioni praticamente identiche.

Analizzando i tempi di addestramento medi, però, si può osservare che
SVM e MLP richiedono molto più tempo per essere addestrate rispetto
agli altri due modelli: \begin{itemize*}
    \item albero decisionale = 84 ms
    \item MLP = 2197 ms
    \item SVM = 826 ms
    \item Gaussian Naive Bayes = 5 ms
\end{itemize*}
L'intervallo di confidenza al $90\%$ del tempo di addestramento è: \begin{itemize*}
    \item albero decisionale = (80 ms, 89 ms)
    \item MLP = (1921 ms, 2474 ms)
    \item SVM = (707 ms, 945 ms)
    \item Gaussian Naive Bayes = (4 ms, 6 ms)
\end{itemize*}

NOTA: i tempi di esecuzione qui riportati non sono identici a quelli rilevati
su Colab. Il tempo di esecuzione dipende infatti da molti fattori, tra cui il 
carico dei server di Google Colab. Si può affermare, però, che i tempi qui
riportati approssimano bene il tempo di addestramento reale.